from lib import LIBRARY
from taichi_core import *
from _logging import warn
import numpy as np

def _null() -> Ptr[byte]:  
    return Ptr[byte]()  # 创建空指针

TiProgram = Ptr[byte]
Error = u32
SUCCESS = Error(TI_ERROR_SUCCESS)
NOT_SUPPORTED = Error(TI_ERROR_NOT_SUPPORTED)
CURROPTED_DATA = Error(TI_ERROR_CORRUPTED_DATA)
NAME_NOT_FOUND = Error(TI_ERROR_NAME_NOT_FOUND)
INVALID_ARGUMENT = Error(TI_ERROR_INVALID_ARGUMENT)
ARGUMENT_NULL = Error(TI_ERROR_ARGUMENT_NULL)
ARGUMENT_OUT_OF_RANGE = Error(TI_ERROR_ARGUMENT_OUT_OF_RANGE)
ARGUMENT_NOT_FOUND = Error(TI_ERROR_ARGUMENT_NOT_FOUND)
INVALID_INTEROP = Error(TI_ERROR_INVALID_INTEROP)
INVALID_STATE = Error(TI_ERROR_INVALID_STATE)
INCOMPATIBLE_MODULE = Error(TI_ERROR_INCOMPATIBLE_MODULE)
OUT_OF_MEMORY = Error(TI_ERROR_OUT_OF_MEMORY)

class TaichiRuntimeError(Static[Exception]):  
    _code: Error
    _message: str
    def __init__(self, code: Error, message: str):  
        super().__init__("TaichiRuntimeError", message)  
        self._code = code 
        self._message = message
  
    def __str__(self):  
        if self.message == "":  
            return f"({self._code})"  
        else:  
            return f"({self._code}) {self.message}"  
  
    @property  
    def code(self) -> Error:  
        return self._code  
  
    @property  
    def message(self) -> str:  
        return self.message

def check_last_error():
    message_size = u64(0)
    code = ti_get_last_error(__ptr__(message_size), _null())
    message = Ptr[byte](int(message_size))
    ti_get_last_error(__ptr__(message_size), message)
    ti_set_last_error(TI_ERROR_SUCCESS, _null())

    if code != TI_ERROR_SUCCESS:
        raise TaichiRuntimeError(Error(code), str.from_ptr(message))

check_last_error()

VULKAN = TI_ARCH_VULKAN
METAL = TI_ARCH_METAL
OPENGL = TI_ARCH_OPENGL
X64 = TI_ARCH_X64
CUDA = TI_ARCH_CUDA
GLES = TI_ARCH_GLES
ARM64 = TI_ARCH_ARM64

Arch = u32
x64 = Arch(0)
arm64 = Arch(1)
js = Arch(2)
cuda = Arch(3)
metal = Arch(4)
opengl = Arch(5)
dx11 = Arch(6)
dx12 = Arch(7)
opencl = Arch(8)
amdgpu = Arch(9)
vulkan = Arch(10)
gles = Arch(11)


class Runtime:  
    _handle: TiRuntime  
    _should_destroy: bool  
      
    def __init__(self, handle: TiRuntime, should_destroy: bool = True):  
        self._handle = handle  
        self._should_destroy = should_destroy  
  
    def __del__(self):  
        self.destroy(quiet=True)  
      
    def destroy(self, quiet: bool = False):  
        if self._should_destroy: 
            if self._handle == _null():
                print("Runtime already destroyed")
                if not quiet:  
                    print("Warning: Runtime.destroy() is called on a null handle.")  
            else:  
                ti_destroy_runtime(self._handle)  
                check_last_error()  
                self._should_destroy = False  
                self._handle = _null()

    @staticmethod 
    def create(arch, device_index: int = 0) -> Runtime:  
        # 手动处理类型转换  
        if isinstance(arch, list):  
            arch_list = arch  
        else:  
            arch_list = [arch]  
        
        handle = _null()  
        for a in arch_list:  
            try:  
                handle = ti_create_runtime(TiArch(a), u32(device_index))    
                check_last_error()  
                break    
            except:    
                continue  
        
        if handle == _null():  
            raise TaichiRuntimeError(NOT_SUPPORTED, "Failed to create runtime")  
        
        return Runtime(handle)

    def wait(self):
        ti_wait(self._handle)
        check_last_error()

    def copy_memory_device_to_device(self, dst, src):  
        dst2 = TiMemorySlice(  
            memory=dst._handle,  
            offset=u64(0),  
            size=dst._size,  
        )  
        src2 = TiMemorySlice(  
            memory=src._handle,  
            offset=u64(0),  
            size=src._size,  
        )
        ti_copy_memory_device_to_device(self._handle, __internal__.class_raw_ptr(dst2),__internal__.class_raw_ptr(src2))  
        check_last_error()

MemoryUsage = u32
STORAGE = MemoryUsage(TI_MEMORY_USAGE_STORAGE_BIT)
UNIFORM = MemoryUsage(TI_MEMORY_USAGE_UNIFORM_BIT)
VERTEX = MemoryUsage(TI_MEMORY_USAGE_VERTEX_BIT)
INDEX = MemoryUsage(TI_MEMORY_USAGE_INDEX_BIT)

class Memory:
    _runtime: Runtime
    _handle: TiMemory
    _size: u64
    _host_access: bool
    _should_destroy: bool
    def __init__(
        self, runtime: Runtime, handle: TiMemory, size: u64, host_access: bool, should_destroy: bool = True
    ):
        self._runtime = runtime
        self._handle = handle
        self._size = size
        self._host_access = host_access
        self._should_destroy = should_destroy
    
    def __del__(self):
        self.free(quiet=True)
    
    @property
    def size(self) -> int:
        return self._size

    @property
    def host_access(self) -> bool:
        return self._host_access
    
    @staticmethod
    def allocate(runtime: Runtime, size: u64, usage: MemoryUsage, host_access: bool = True):
        allocate_info = TiMemoryAllocateInfo(
            size=size,                    # u64类型
            host_write=TI_TRUE if host_access else TI_FALSE,
            host_read=TI_TRUE if host_access else TI_FALSE, 
            export_sharing=TI_FALSE,
            usage=usage
        )
        handle = ti_allocate_memory(runtime._handle, __internal__.class_raw_ptr(allocate_info))
        check_last_error()
        return Memory(runtime, handle, size=size, host_access=host_access)

    def free(self, quiet: bool = False):
        if self._should_destroy:
            if self._handle == _null():
                if not quiet:
                    warn("Memory.free() is called on a null handle.".c_str())
            else:
                ti_free_memory(self._runtime._handle, self._handle)
                check_last_error()
                self._should_destroy = False
                self._handle = TiMemory(0)


    def read(self, dst, force: bool = False):  
        assert u64(len(dst)) == self._size, f"len(dst) ({len(dst)}) != self._size ({self._size})"  

        if self._host_access:  
            mapped = ti_map_memory(self._runtime._handle, self._handle)  
            check_last_error()  
            assert mapped != _null()
            from internal.gc import alloc  
            src_ptr = Ptr[byte](mapped)
            str.memcpy(dst.ptr, src_ptr, int(self._size))  
    
            ti_unmap_memory(self._runtime._handle, self._handle)  
            check_last_error()  
        elif force:  
            staging_buffer = Memory.allocate(  
                self._runtime, size=self._size, usage=STORAGE,
            )  
            self._runtime.copy_memory_device_to_device(staging_buffer, self)  
            self._runtime.wait()  
            staging_buffer.read(dst)   
            del staging_buffer
        else:  
            raise TaichiRuntimeError(  
                NOT_SUPPORTED,  
                "Memory.read() is not supported when `host_access` is False. Use `force=True` to force copying to host.",  
            )

    def write(self, src, force: bool = False):    
        assert u64(len(src)) == self._size, f"len(src) ({len(src)}) != self._size ({self._size})"  
    
        if self._host_access:  
            mapped = ti_map_memory(self._runtime._handle, self._handle)  
            check_last_error()  
            assert mapped
            dst_ptr = Ptr[byte](mapped)  # 假设mapped返回指针  
            str.memcpy(dst_ptr, src.ptr, int(self._size))  
            ti_unmap_memory(self._runtime._handle, self._handle)  
            check_last_error()  
        elif force:  
            staging_buffer = Memory.allocate(  
                self._runtime, size=self._size, usage=STORAGE, host_access=True 
            ) 
            staging_buffer.write(src)
            self._runtime.copy_memory_device_to_device(self, staging_buffer)  
            self._runtime.wait()   
            staging_buffer.free()
        else:  
            raise TaichiRuntimeError(  
                NOT_SUPPORTED,  
                "Memory.write() is not supported when `host_access` is False. Use `force=True` to force copying to host.",  
            )

    @staticmethod  
    def from_bytes(runtime, src, host_access: bool = True):  
        # 移除类型注解和关键字参数强制语法  
        # assert isinstance(src, ByteString)  # Codon中移除类型检查  
        
        memory = Memory.allocate(runtime, size=u64(len(src)), usage=STORAGE,host_access=host_access)  
        memory.write(src, force=True)  
        return memory
    
    def to_bytes(self):  
        from internal.gc import alloc  
        size = int(self._size)  # 转换为 int  
        p = alloc_atomic(size)  # 分配内存  
        dst = str(Ptr[byte](p), size)  # 创建字符串
        self.read(dst, force=True)  
        return dst

DataType = u32
F16 = DataType(TI_DATA_TYPE_F16)
F32 = DataType(TI_DATA_TYPE_F32)
F64 = DataType(TI_DATA_TYPE_F64)
I8 = DataType(TI_DATA_TYPE_I8)
I16 = DataType(TI_DATA_TYPE_I16)
I32 = DataType(TI_DATA_TYPE_I32)
I64 = DataType(TI_DATA_TYPE_I64)
U8 = DataType(TI_DATA_TYPE_U8)
U16 = DataType(TI_DATA_TYPE_U16)
U32 = DataType(TI_DATA_TYPE_U32)
U64 = DataType(TI_DATA_TYPE_U64)

_DTYPE_SIZE_TABLE = {
    TI_DATA_TYPE_F16: 2,
    TI_DATA_TYPE_F32: 4,
    TI_DATA_TYPE_F64: 8,
    TI_DATA_TYPE_I8: 1,
    TI_DATA_TYPE_I16: 2,
    TI_DATA_TYPE_I32: 4,
    TI_DATA_TYPE_I64: 8,
    TI_DATA_TYPE_U8: 1,
    TI_DATA_TYPE_U16: 2,
    TI_DATA_TYPE_U32: 4,
    TI_DATA_TYPE_U64: 8,
}

_NP_DTYPE_TABLE: Dict[str, DataType] = {
    "float16": F16,
    "float32": F32,
    "float64": F64,
    "int8": I8,
    "int16": I16,
    "int32": I32,
    "int64": I64,
    "uint8": U8,
    "uint16": U16,
    "uint32": U32,
    "uint64": U64,
}

class NdArray:  
    _runtime: Runtime  
    _memory: Memory  
    _shape: DynamicTuple[int]  
    _elem_shape: DynamicTuple[int]  
    _elem_type: DataType

    def __init__(  
        self,   
        runtime: Runtime,   
        memory: Memory,
        shape: DynamicTuple[int],   
        elem_shape: DynamicTuple[int],   
        elem_type: DataType  
    ):  
        self._runtime = runtime  
        self._memory = memory  
        self._shape = shape  
        self._elem_shape = elem_shape  
        self._elem_type = elem_type  
  
    def __del__(self):  
        self.free()  
  
    @property  
    def memory(self) -> Memory:  
        return self._memory  
  
    @property  
    def shape(self) -> Tuple[int]:  
        return self._shape  
  
    @property  
    def elem_shape(self) -> Tuple[int]:  
        return self._elem_shape  
  
    @property  
    def elem_type(self) -> DataType:  
        return self._elem_type  
  
    @staticmethod  
    def allocate(  
        runtime: Runtime,  
        elem_type: DataType,
        shape: List[int],
        elem_shape: List[int], 
        host_access: bool = True,  
    ) -> NdArray: 

        shape_size = 1  
        for dim in shape:  
            shape_size *= dim  
        
        elem_shape_size = 1  
        for dim in elem_shape:  
            elem_shape_size *= dim  
        
        size = shape_size * elem_shape_size * _DTYPE_SIZE_TABLE[elem_type]  
        memory = Memory.allocate(runtime, size=u64(size), host_access=host_access, usage=STORAGE)  
        return NdArray(runtime, memory, shape= DynamicTuple(shape), elem_shape=DynamicTuple(elem_shape), elem_type=elem_type)
    
    def free(self):  
        self._memory.free()

    @staticmethod
    def from_numpy(  
        runtime: Runtime,  
        arr: np.ndarray,
        shape: Optional[List[int]] = None,  
        elem_shape: Optional[List[int]] = None,  
        elem_type: Optional[DataType] = None,  
        host_access: bool = True,  
    ) -> NdArray:  
        # 直接访问Codon NumPy数组的属性  
        arr_shape = arr.shape  
        arr_dtype = arr.dtype  
        # 确定元素类型  
        if elem_type is None:  
            elem_type2 = _NP_DTYPE_TABLE[arr_dtype.__name__]
        else:  
            elem_type2 = elem_type  
    
        # 确定元素形状 - 修复Optional处理  
        if elem_shape is None:  
            elem_shape2 = DynamicTuple[int]()  
        else:  
            # 确保elem_shape中没有None值  
            elem_shape_list = []  
            for val in elem_shape:  
                if val is None:  
                    raise ValueError("elem_shape cannot contain None values")  
                elem_shape_list.append(val)  
            
            elem_shape2 = DynamicTuple(elem_shape_list)
            
            if len(elem_shape2) > len(arr_shape):  
                raise ValueError("elem_shape cannot be longer than array shape")  
            
            # 现在可以安全地比较int类型  
            for i in range(len(elem_shape2)):  
                arr_idx = len(arr_shape) - len(elem_shape2) + i  
                if arr_shape[arr_idx] != elem_shape2[i]:  
                    raise ValueError(f"Shape mismatch at index {arr_idx}")  
    
        if shape is None:
            arr_shape_dyn = DynamicTuple(arr_shape)
            shape2 = arr_shape_dyn[:(len(arr_shape) - len(elem_shape2))]  
        else:  
            # 确保shape中没有None值  
            shape_list = []  
            for val in shape:  
                if val is None:  
                    raise ValueError("shape cannot contain None values")  
                shape_list.append(val)  
            shape2 = DynamicTuple(shape_list)  
            
            if len(shape2) > len(arr_shape):  
                raise ValueError("shape cannot be longer than array shape")  
            
            # 现在可以安全地比较int类型  
            for i in range(len(shape2)):  
                if arr_shape[i] != shape2[i]:  
                    raise ValueError(f"Shape mismatch at index {i}")  
    
        # 获取数组字节数据  
        arr_bytes = arr.tobytes()  
        memory = Memory.from_bytes(runtime, arr_bytes, host_access=True)  
        
        return NdArray(runtime, memory, shape=shape2, elem_shape=elem_shape2, elem_type=elem_type2)

    def to_numpy_float32_1d(self) -> np.ndarray[np.float32, 1]:
        buffer_data = self._memory.to_bytes()
        all_shape = list(self._shape) + list(self._elem_shape)
        
        total_elements = 1
        for dim in all_shape:
            total_elements *= dim
        
        arr = np.frombuffer(buffer_data, dtype=np.float32, count=total_elements)
        return arr  # 直接返回1D数组
    
    def to_numpy_float32_2d(self) -> np.ndarray[np.float32, 2]:
        buffer_data = self._memory.to_bytes()
        all_shape = list(self._shape) + list(self._elem_shape)
        
        total_elements = 1
        for dim in all_shape:
            total_elements *= dim
        
        arr = np.frombuffer(buffer_data, dtype=np.float32, count=total_elements)
        
        # 确保有至少2个维度用于reshape
        if len(all_shape) >= 2:
            return arr.reshape(all_shape[0], all_shape[1])
        elif len(all_shape) == 1:
            return arr.reshape(all_shape[0], 1)  # 转换为(n, 1)的2D数组
        else:
            return arr.reshape(1, 1)  # 标量转换为(1, 1)的2D数组
    
    def to_numpy_int32_1d(self) -> np.ndarray[np.int32, 1]:
        buffer_data = self._memory.to_bytes()
        all_shape = list(self._shape) + list(self._elem_shape)
        
        total_elements = 1
        for dim in all_shape:
            total_elements *= dim
        
        arr = np.frombuffer(buffer_data, dtype=np.int32, count=total_elements)
        return arr  # 直接返回1D数组
    
    def to_numpy_int32_2d(self) -> np.ndarray[np.int32, 2]:
        buffer_data = self._memory.to_bytes()
        all_shape = list(self._shape) + list(self._elem_shape)
        
        total_elements = 1
        for dim in all_shape:
            total_elements *= dim
        
        arr = np.frombuffer(buffer_data, dtype=np.int32, count=total_elements)
        
        # 确保有至少2个维度用于reshape
        if len(all_shape) >= 2:
            return arr.reshape(all_shape[0], all_shape[1])
        elif len(all_shape) == 1:
            return arr.reshape(all_shape[0], 1)  # 转换为(n, 1)的2D数组
        else:
            return arr.reshape(1, 1)  # 标量转换为(1, 1)的2D数组
    
    def to_numpy_int64_1d(self) -> np.ndarray[np.int64, 1]:
        buffer_data = self._memory.to_bytes()
        all_shape = list(self._shape) + list(self._elem_shape)
        
        total_elements = 1
        for dim in all_shape:
            total_elements *= dim
        
        arr = np.frombuffer(buffer_data, dtype=np.int64, count=total_elements)
        return arr  # 直接返回1D数组
    
    def to_numpy_int64_2d(self) -> np.ndarray[np.int64, 2]:
        buffer_data = self._memory.to_bytes()
        all_shape = list(self._shape) + list(self._elem_shape)
        
        total_elements = 1
        for dim in all_shape:
            total_elements *= dim
        
        arr = np.frombuffer(buffer_data, dtype=np.int64, count=total_elements)
        
        # 确保有至少2个维度用于reshape
        if len(all_shape) >= 2:
            return arr.reshape(all_shape[0], all_shape[1])
        elif len(all_shape) == 1:
            return arr.reshape(all_shape[0], 1)  # 转换为(n, 1)的2D数组
        else:
            return arr.reshape(1, 1)  # 标量转换为(1, 1)的2D数组


class AotModule:
    _runtime: Runtime  
    _handle: TiAotModule
    _should_destroy: bool 
    def __init__(self, runtime: Runtime, handle: TiAotModule, should_destroy: bool = True):  
        self._runtime = runtime  
        self._handle = handle  
        self._should_destroy = should_destroy  
  
    def __del__(self):  
        self.destroy(quiet=True)  
  
    @staticmethod  
    def load(runtime: Runtime, path: str):  
        # Convert string to bytes for C API  
        # path_bytes = path.encode("ascii")  
        # handle = ti_load_aot_module(runtime._handle, __ptr__(path_bytes))  
        handle = ti_load_aot_module(runtime._handle, path.c_str())
        check_last_error()  
        return AotModule(runtime, handle)  
  
    @staticmethod  
    def create(runtime: Runtime, tcm: str):  # Changed from bytes to str  
        # Convert string to bytes and get length  
        # tcm_bytes = tcm.encode("utf-8")
        tcm_bytes = tcm.c_str()
        tcm_len = u64(len(tcm_bytes))  
        handle = ti_create_aot_module(runtime._handle, tcm_bytes, tcm_len)  
        check_last_error()  
        return AotModule(runtime, handle)  
  
    def destroy(self, quiet: bool = False):  
        if self._should_destroy:  
            if not self._handle:  # Check for null pointer  
                if not quiet:  
                    print("Warning: AotModule.destroy() is called on a null handle.")  
            else:  
                ti_destroy_aot_module(self._handle)  
                check_last_error()  
                self._should_destroy = False  
                self._handle = TiAotModule()  # Set to null  

class ArgumentType:
    I32 = 0
    F32 = 1
    NDARRAY = 2


class Argument:
    _ty: int
    _value: TiArgumentValue
    
    def __init__(self, value):
        if isinstance(value, int):
            ty = ArgumentType.I32
            value2 = TiArgumentValue(i32(value),float32(0),TiNdArray())  # 直接构造联合体
        elif isinstance(value, float):
            ty = ArgumentType.F32
            value2 = TiArgumentValue(i32(0),float32(value),TiNdArray())  # 直接构造联合体
        elif isinstance(value, NdArray):
            ty = ArgumentType.NDARRAY
            
            # 创建 shape 数组
            shape_dims = Array[u32](16)
            for i in range(len(value._shape)):
                shape_dims[i] = u32(value._shape[i])
                print(f"i: {i},shape_dims[i]:{shape_dims[i]}");
            for i in range(len(value._shape), 16):
                shape_dims[i] = u32(0)
            shape_tuple: tuple[u32, u32, u32, u32, u32, u32, u32, u32,
                   u32, u32, u32, u32, u32, u32, u32, u32] = (
                shape_dims[0],  shape_dims[1],  shape_dims[2],  shape_dims[3],
                shape_dims[4],  shape_dims[5],  shape_dims[6],  shape_dims[7],
                shape_dims[8],  shape_dims[9],  shape_dims[10], shape_dims[11],
                shape_dims[12], shape_dims[13], shape_dims[14], shape_dims[15]
            )
            shape = TiNdShape(
                dim_count=u32(len(value._shape)),
                dims=shape_tuple
            )

            # 创建 elem_shape 数组
            elem_shape_dims = shape_dims = Array[u32](16)
            for i in range(len(value._elem_shape)):
                elem_shape_dims[i] = u32(value._elem_shape[i])
            for i in range(len(value._elem_shape), 16):
                elem_shape_dims[i] = u32(0)

            elem_shape_tuple: tuple[u32, u32, u32, u32, u32, u32, u32, u32,
                   u32, u32, u32, u32, u32, u32, u32, u32] = (
                elem_shape_dims[0],  elem_shape_dims[1],  elem_shape_dims[2],  elem_shape_dims[3],
                elem_shape_dims[4],  elem_shape_dims[5],  elem_shape_dims[6],  elem_shape_dims[7],
                elem_shape_dims[8],  elem_shape_dims[9],  elem_shape_dims[10], elem_shape_dims[11],
                elem_shape_dims[12], elem_shape_dims[13], elem_shape_dims[14], elem_shape_dims[15]
            )
            
            elem_shape = TiNdShape(
                dim_count=u32(len(value._elem_shape)),
                dims=elem_shape_tuple,
            )
            
            x = TiNdArray(
                memory=value._memory._handle,
                shape=shape,
                elem_shape=elem_shape,
                elem_type=value._elem_type,
            )
            print(value._memory._handle)
            value2 = TiArgumentValue(i32(0),float32(0.0),x)
        else:
            raise TaichiRuntimeError(Error.NOT_SUPPORTED, f"{type(value)} is not a valid argument type.")
        
        self._ty = ty
        self._value = value2 



class Kernel:  
    _aot_module: AotModule
    _name: str  
    _handle: TiAotModule
    def __init__(self, aot_module, name: str, handle: TiAotModule):  
        self._aot_module = aot_module  
        self._name = name  
        self._handle = handle  
  
    def __call__(self, *args):  # Remove Any type annotation  
        self.launch(*args)
    
    def launch(self, *args) -> None:    
        print(f"启动 kernel，参数数量: {len(args)}")
        
        # 转换参数    
        args2: List[Argument] = []    
        for i, arg in enumerate(args):    
            print(f"参数 {i}: 类型 {type(arg)}")
            
            if isinstance(arg, Argument):
                tmp = arg   
                args2.append(arg)    
            else:
                tmp = Argument(arg)    
                args2.append(Argument(arg))
        
        # 创建TiArgument列表    
        args3: List[TiArgument] = []    
        for i, arg in enumerate(args2):
            print(f"TiArgument {i}: type={arg._ty}")
            args3.append(TiArgument(u32(arg._ty),arg._value))  

        args4 = Ptr[TiArgument](len(args3))  
        for i in range(len(args3)):  
            args4[i] = args3[i]
        print(f"dims_count:{args4[0].value.ndarray.shape.dim_count}")
        print(f"shape[0]: {args4[0].value.ndarray.shape.dims[0]}")
        print(f"shape[1]: {args4[0].value.ndarray.shape.dims[1]}")
        print(f"args4: {args4}")
        tmp = args[0]
        ti_launch_kernel(
            self._aot_module._runtime._handle,    
            self._handle,    
            u32(len(args3)),    
            args4
        )
        
        check_last_error()


def get_kernel(aot_module: AotModule, name: str) -> Kernel: 
    # name_bytes = name.encode("utf-8")
    name_bytes = name.c_str()
    handle = ti_get_aot_module_kernel(aot_module._handle, name_bytes)  
    check_last_error()  
    return Kernel(aot_module, name, handle)



